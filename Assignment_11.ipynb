{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fdaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Write the Python code to implement a single neuron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18959d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5016238187244485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, input_size):\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        total = np.dot(inputs, self.weights) + self.bias\n",
    "        output = sigmoid(total)\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_data = np.array([0.5, 0.3, 0.2])\n",
    "neuron = Neuron(input_size=3)\n",
    "output = neuron.forward(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7ddd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdec793",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Write the Python code to implement ReLU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2889f3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Example usage\n",
    "input_data = np.array([-1, 2, -3, 4])\n",
    "output = relu(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eac3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Write the Python code for a dense layer in terms of matrix multiplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15fa3aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.6964774   -5.39947716]\n",
      " [ -1.47146202 -14.41064285]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = np.dot(inputs, self.weights) + self.bias\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_data = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "dense_layer = DenseLayer(input_size=3, output_size=2)\n",
    "output = dense_layer.forward(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547aa94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions\n",
    "and functionality built into Python).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f605efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44595892527931114, 2.9727141380982665]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = [sum(weight * input_value for weight, input_value in zip(row, inputs)) + bias\n",
    "                  for row, bias in zip(self.weights, self.bias)]\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_data = [1, 2, 3]\n",
    "dense_layer = DenseLayer(input_size=3, output_size=2)\n",
    "output = dense_layer.forward(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ecdc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What is the “hidden size” of a layer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adcc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The \"hidden size\" of a layer refers to the number of neurons or units in that layer. It represents the dimensionality or number of output values produced by that layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4e143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What does the t method do in PyTorch?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In PyTorch, the t method is used to transpose a tensor. It swaps the dimensions of the tensor, turning rows into columns and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc11c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Why is matrix multiplication written in plain Python very slow?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba31a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix multiplication written in plain Python is slow because it involves nested loops and individual element-wise multiplications, resulting in a high computational complexity. Python's built-in list comprehensions and lack of optimized matrix operations make it inefficient for large-scale matrix multiplication compared to libraries like NumPy or frameworks like PyTorch, which are implemented in lower-level languages and have highly optimized matrix multiplication algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508b16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. In matmul, why is ac==br?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893611ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "In matrix multiplication (matmul), the condition ac == br ensures that the inner dimensions of the two matrices being multiplied are the same. The matrices a and b should have dimensions (a_rows, a_cols) and (b_rows, b_cols), respectively, where a_cols must be equal to b_rows for the multiplication to be valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95705faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22539560",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c093001",
   "metadata": {},
   "outputs": [],
   "source": [
    "In Jupyter Notebook, we can measure the time taken for a single cell to execute using the %%timeit magic command. Simply prepend %%timeit at the beginning of the cell and run it. The command will automatically execute the cell multiple times and provide information about the average execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06970aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. What is elementwise arithmetic?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Elementwise arithmetic refers to performing arithmetic operations (addition, subtraction, multiplication, division, etc.) on corresponding elements of two or more tensors or matrices. Each element in one tensor is paired with the corresponding element in another tensor, and the operation is applied element-wise. This operation is possible when the tensors have compatible shapes or can be broadcasted to match each other's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252db1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Write the PyTorch code to test whether every element of a is greater than the\n",
    "corresponding element of b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d544de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([0, 2, 2])\n",
    "\n",
    "result = torch.all(a > b)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0fa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77794714",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. What is a rank-0 tensor? How do you convert it to a plain Python data type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43910ed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m scalar_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([])\n\u001b[1;32m----> 5\u001b[0m scalar \u001b[38;5;241m=\u001b[39m \u001b[43mscalar_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(scalar)\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "scalar_tensor = torch.tensor([])\n",
    "\n",
    "scalar = scalar_tensor.item()\n",
    "print(scalar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b8082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. How does elementwise arithmetic help us speed up matmul?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Elementwise arithmetic helps speed up matrix multiplication by allowing parallelization and vectorization of computations. Rather than performing individual multiplications and additions in a loop, elementwise operations can be executed in parallel, leveraging optimized routines provided by libraries like NumPy or PyTorch. This enables more efficient utilization of hardware resources and takes advantage of hardware acceleration, resulting in significant speed improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953c383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cee037",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. What are the broadcasting rules?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d42774",
   "metadata": {},
   "outputs": [],
   "source": [
    "Broadcasting rules determine how two tensors with different shapes can be combined or operated upon element-wise. The rules define conditions under which two tensors can be broadcasted to have compatible shapes for elementwise operations. The broadcasting rules are as follows:\n",
    "\n",
    "If the tensors have the same number of dimensions, but one or more dimensions differ in size, the tensor with size 1 in a particular dimension is broadcasted to match the size of the corresponding dimension in the other tensor.\n",
    "\n",
    "If one of the tensors has fewer dimensions than the other, 1s are prepended to its shape to match the number of dimensions.\n",
    "\n",
    "If the size of a dimension in one tensor is 1, and the size of the same dimension in the other tensor is greater than 1, the tensor with size 1 is broadcasted along that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d9330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc391217",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. What is expand_as? Show an example of how it can be used to match the results of\n",
    "broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf26fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "The expand_as method in PyTorch is used to expand the size of a tensor to match the size of another tensor. It takes the shape of the target tensor as an argument and returns a new tensor with the expanded size. It can be used to match the results of broadcasting. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ec5a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "expanded_a = a.expand_as(b)\n",
    "print(expanded_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030d385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6f8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75939a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc961979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fa4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115152a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922be115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
