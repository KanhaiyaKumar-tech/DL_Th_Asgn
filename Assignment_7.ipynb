{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadbc88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1574b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Can you think of a few applications for a sequence-to-sequence RNN? What about a\n",
    "sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f91424",
   "metadata": {},
   "outputs": [],
   "source": [
    "Applications for different types of RNNs:\n",
    "- Sequence-to-sequence RNN: This type of RNN is commonly used in machine translation, where a sequence of words in one language is translated into another language. It is also used in chatbot systems for generating responses based on an input sequence of words. Other applications include speech recognition, text summarization, and image captioning.\n",
    "- Sequence-to-vector RNN: This type of RNN is useful for tasks where the input sequence is variable in length, but the output is a fixed-size representation. One application is sentiment analysis, where a variable-length text sequence is classified into positive or negative sentiment. It can also be used for document classification, where a variable-length document is mapped to a fixed-size vector representation.\n",
    "- Vector-to-sequence RNN: This type of RNN takes a fixed-size input vector and generates a variable-length sequence. One application is text generation, where a fixed-size vector (e.g., a latent space representation) is used to generate a sequence of words. It can also be used for music generation, where a fixed-size input vector is used to generate a sequence of musical notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae343fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. How many dimensions must the inputs of an RNN layer have? What does each dimension\n",
    "represent? What about its outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "The inputs of an RNN layer must have three dimensions: (batch_size, timesteps, input_features). Each dimension represents:\n",
    "- Batch size: The number of sequences processed in parallel during training or inference.\n",
    "- Timesteps: The number of time steps or sequence length in each input sequence.\n",
    "- Input features: The number of features or dimensions in each time step of the input sequence.\n",
    "\n",
    "The outputs of an RNN layer also have three dimensions: (batch_size, timesteps, output_features). The output features represent the hidden state or output of the RNN at each time step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004279eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should\n",
    "have return_sequences=True? What about a sequence-to-vector RNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a deep sequence-to-sequence RNN, RNN layers that should have `return_sequences=True` are the ones that need to output a sequence. These layers will pass the hidden state or output at each time step to the next layer. For example, in an encoder-decoder architecture for machine translation, all the encoder RNN layers would have `return_sequences=True` to pass the encoded sequence to the decoder.\n",
    "\n",
    "For a sequence-to-vector RNN, only the last RNN layer needs to have `return_sequences=False` (the default value). The final hidden state or output of the last time step will be passed to subsequent layers or used as the final output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c88573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "4. Suppose you have a daily univariate time series, and you want to forecast the next seven\n",
    "days. Which RNN architecture should you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "For forecasting the next seven days of a daily univariate time series, a suitable RNN architecture to use is the Sequence-to-Vector RNN. The model would take the past observations as input and predict the next seven days as a vector output. The architecture would typically involve one or more recurrent layers followed by one or more dense layers with an appropriate activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bc6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981256c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What are the main difficulties when training RNNs? How can you handle them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Difficulties when training RNNs include:\n",
    "- Vanishing or exploding gradients: RNNs are prone to the vanishing gradient problem, where gradients can diminish or explode exponentially over long sequences. This can lead to difficulties in training the network. Techniques such as gradient clipping, parameter initialization, and using alternative RNN architectures like LSTMs and GRUs can help mitigate this issue.\n",
    "- Long-term dependencies: RNNs have difficulty capturing dependencies that span long sequences, as the influence of earlier inputs diminishes over time. Architectures such as LSTMs and GRUs address this issue by using gating mechanisms to selectively propagate relevant information over longer time steps.\n",
    "- Overfitting: RNNs can be prone to overfitting, especially when dealing with small datasets or complex models. Regularization techniques such as dropout, weight decay, and early stopping can be used to prevent overfitting.\n",
    "- Computational efficiency: Training RNNs can be computationally expensive, especially for long sequences. Techniques such as mini-batch training, optimizing the implementation, and utilizing hardware accelerators (e.g., GPUs) can help improve training efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ef535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Can you sketch the LSTM cell’s architecture?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "The LSTM (Long Short-Term Memory) cell's architecture consists of three main components: an input gate, a forget gate, and an output gate. These gates control the flow of information within the cell. The input gate regulates how much new information is added to the cell state, the forget gate determines how much information from the previous cell state is retained, and the output gate controls the flow of information from the cell state to the output.\n",
    "\n",
    "Here is a sketch of the LSTM cell's architecture:\n",
    " \n",
    "            Input\n",
    "              ↓\n",
    "        ┌────────────┐\n",
    "        │            │\n",
    "        │            ▼\n",
    "      ╔═════╗    ╔═════╗\n",
    "      ║       ║    ║       ║\n",
    "    → ║       ║    ║       ║ →\n",
    "      ║       ║    ║       ║\n",
    "      ║       ║    ║       ║\n",
    "    ──╚═════╝────╚═════╝──\n",
    "        ↑\n",
    "        │\n",
    "        └────────────┐\n",
    "                     │\n",
    "                     ▼\n",
    "                  Output\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1fef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Why would you want to use 1D convolutional layers in an RNN?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1D convolutional layers can be used in an RNN to capture local patterns or features within a sequence. They can extract features from smaller windows of the sequence, similar to how spatial features are extracted from local receptive fields in convolutional neural networks. This can help in learning local dependencies or patterns that are relevant to the task at hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5750b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Which neural network architecture could you use to classify videos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e78c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "To classify videos, a suitable neural network architecture is a 3D convolutional network, often referred to as C3D. This architecture extends the concept of 2D convolutional networks to video data by incorporating an additional dimension (time) along with spatial dimensions. The 3D convolutional layers capture spatiotemporal patterns and dependencies in video sequences. The extracted features are then fed to fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1969f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eccede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e9178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15240d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481bb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96ee6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabbdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c4123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b85f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a992e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8b82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b3d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c51b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b9010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d52a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c888ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089039c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf789f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9a576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cdcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644ef33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776642e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904b69e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
